{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using NannyML Concept Shift Algorithm from AWS Marketplace "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Overview\n",
    "\n",
    "Machine Learning Models are able to learn a relationship between some variables, **X** and a target Y.\n",
    "The relationship - otherwise called concept - learnt from the training data is static.\n",
    "However the world in which our model operates is not static.\n",
    "We expand in the possible types of change in our blog [Understanding Data Shift](https://www.nannyml.com/blog/types-of-data-shift).\n",
    "Here we focus on Concept Shift and present an algorithm that captures its impact.\n",
    "\n",
    "## Algorithm Overview\n",
    "\n",
    "How do we measure the impact of Concept Shift? This is a complex problem, our data rarely, if ever contains just concept shift for us to measure it in a straightforward way. In order to measure only the effects of Concept Shift our algorithm answers the following question:\n",
    "\n",
    "**What would the performance of my model be on the reference dataset, if the world works as described by the current data.**\n",
    "\n",
    "In the place of current data we use the data contained in the [data chunk](https://nannyml.readthedocs.io/en/stable/glossary.html#term-Data-Chunk)\n",
    "for which we are estimaing the impact of Concept Shift.\n",
    "\n",
    "The algorithm consists of the following steps:\n",
    "\n",
    "1. Learn the latest concept from model feature columns and targets on chunk data.\n",
    "2. Make predictions on reference data using learnt concept model.\n",
    "3. Estimate the performance of the client model assuming learnt concept predictions are ground truth.\n",
    "\n",
    "> **Note**: This is a reference notebook and it cannot run unless you make changes suggested in the notebook.\n",
    "\n",
    "## Pre-requisites\n",
    "1. **Note**: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**\n",
    "1. Some hands-on experience using [Amazon SageMaker](https://aws.amazon.com/sagemaker/).\n",
    "1. To use this algorithm successfully, ensure that:\n",
    "    1. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used: \n",
    "        1. **aws-marketplace:ViewSubscriptions**\n",
    "        1. **aws-marketplace:Unsubscribe**\n",
    "        1. **aws-marketplace:Subscribe**  \n",
    "    2. or your AWS account has a subscription to [Model Concept Shift Detection - NannyML](https://aws.amazon.com/marketplace/pp/prodview-64nptz3lrs4gc). \n",
    "\n",
    "## Contents\n",
    "1. [Subscribe to the algorithm](#1.-Subscribe-to-the-algorithm)\n",
    "1. [Prepare dataset](#2.-Prepare-dataset)\n",
    "\t1. [Dataset format expected by the algorithm](#A.-Dataset-format-expected-by-the-algorithm)\n",
    "\t1. [Visualize reference dataset](#B.-Visualize-reference-dataset)\n",
    "\t1. [Upload datasets to Amazon S3](#C.-Upload-datasets-to-Amazon-S3)\n",
    "1. [Train the machine learning algorithm](#3:-Train-the-machine-learning-algorithm)\n",
    "\t1. [Set up environment](#3.1-Set-up-environment)\n",
    "\t1. [Train a model](#3.2-Train-the-algorithm)\n",
    "1. [Deploy model](#4:-Deploy-model)\n",
    "1. [Perform Batch Inference](#5.-Perform-Batch-Inference)\n",
    "1. [Clean-up](#6.-Clean-up)\n",
    "\t1. [Delete the model](#A.-Delete-the-model)\n",
    "\t1. [Unsubscribe to the listing (optional)](#B.-Unsubscribe-to-the-listing-(optional))\n",
    "\n",
    "\n",
    "## Usage instructions\n",
    "You can run this notebook one cell at a time (By using Shift+Enter for running a cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Subscribe to the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To subscribe to the algorithm:\n",
    "1. Open the algorithm listing page [Model Concept Shift Detection - NannyML](https://aws.amazon.com/marketplace/pp/prodview-64nptz3lrs4gc)\n",
    "1. On the AWS Marketplace listing,  click on **Continue to subscribe** button.\n",
    "1. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you agree with EULA, pricing, and support terms. \n",
    "1. Once you click on **Continue to configuration button** and then choose a **region**, you will see a **Product Arn**. This is the algorithm ARN that you need to specify while training a custom ML model. Copy the ARN corresponding to your region and specify the same in the following cell.\n",
    "\n",
    "<font color='red'>Directly copy your assigned ARN code below:<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "algo_arn = \"<Customer to specify algorithm ARN corresponding to their AWS region>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Dataset format expected by the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently the Concept Shift detection algorithm only works for Binary Classification problems. \n",
    "Hence for this notebook we will be using \n",
    "[NannyML's synthetic car loan dataset](https://nannyml.readthedocs.io/en/stable/datasets/binary_car_loan.html).\n",
    "\n",
    "More detailed information on what data are required can be found on [NannyML's Data Requirements Documentation](https://nannyml.readthedocs.io/en/stable/tutorials/data_requirements.html).\n",
    "\n",
    "For AWS Algorithm marketplace it's best if data are provided in a CSV format. You can find some information about dataset format in **Usage Information** section of [Model Concept Shift Detection - NannyML](https://aws.amazon.com/marketplace/pp/prodview-64nptz3lrs4gc).\n",
    "<br>\n",
    "\n",
    "<font color='red'>Edit code below as appropriate for the Machine Learning problem type you are interested in:<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Visualize reference dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car_value</th>\n",
       "      <th>salary_range</th>\n",
       "      <th>debt_to_income_ratio</th>\n",
       "      <th>loan_length</th>\n",
       "      <th>repaid_loan_on_prev_car</th>\n",
       "      <th>size_of_downpayment</th>\n",
       "      <th>driver_tenure</th>\n",
       "      <th>repaid</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>y_pred_proba</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39811.0</td>\n",
       "      <td>40K - 60K €</td>\n",
       "      <td>0.632950</td>\n",
       "      <td>19.0</td>\n",
       "      <td>False</td>\n",
       "      <td>40%</td>\n",
       "      <td>0.212653</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-01-01 00:00:00.000</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12679.0</td>\n",
       "      <td>40K - 60K €</td>\n",
       "      <td>0.718627</td>\n",
       "      <td>7.0</td>\n",
       "      <td>True</td>\n",
       "      <td>10%</td>\n",
       "      <td>4.927549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-01-01 00:08:43.152</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19847.0</td>\n",
       "      <td>40K - 60K €</td>\n",
       "      <td>0.721724</td>\n",
       "      <td>17.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.520817</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-01-01 00:17:26.304</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22652.0</td>\n",
       "      <td>20K - 20K €</td>\n",
       "      <td>0.705992</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>10%</td>\n",
       "      <td>0.453649</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-01-01 00:26:09.456</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21268.0</td>\n",
       "      <td>60K+ €</td>\n",
       "      <td>0.671888</td>\n",
       "      <td>21.0</td>\n",
       "      <td>True</td>\n",
       "      <td>30%</td>\n",
       "      <td>5.695263</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-01-01 00:34:52.608</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   car_value salary_range  debt_to_income_ratio  loan_length  \\\n",
       "0    39811.0  40K - 60K €              0.632950         19.0   \n",
       "1    12679.0  40K - 60K €              0.718627          7.0   \n",
       "2    19847.0  40K - 60K €              0.721724         17.0   \n",
       "3    22652.0  20K - 20K €              0.705992         16.0   \n",
       "4    21268.0       60K+ €              0.671888         21.0   \n",
       "\n",
       "   repaid_loan_on_prev_car size_of_downpayment  driver_tenure  repaid  \\\n",
       "0                    False                 40%       0.212653     1.0   \n",
       "1                     True                 10%       4.927549     0.0   \n",
       "2                    False                  0%       0.520817     1.0   \n",
       "3                    False                 10%       0.453649     1.0   \n",
       "4                     True                 30%       5.695263     1.0   \n",
       "\n",
       "                 timestamp  y_pred_proba  y_pred  \n",
       "0  2018-01-01 00:00:00.000          0.99       1  \n",
       "1  2018-01-01 00:08:43.152          0.07       0  \n",
       "2  2018-01-01 00:17:26.304          1.00       1  \n",
       "3  2018-01-01 00:26:09.456          0.98       1  \n",
       "4  2018-01-01 00:34:52.608          0.99       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_dataset = \"data/synthetic_car_loan_reference.csv\"\n",
    "pd.read_csv(reference_dataset).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Upload datasets to Amazon S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "sagemaker_session = sage.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "# Uncomment below to see selected default bucket\n",
    "# bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "demo_prefix = \"doc-notebook-demo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reference_data = sagemaker_session.upload_data(\n",
    "    reference_dataset, bucket=bucket, key_prefix=demo_prefix\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Train the machine learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that dataset is available in an accessible Amazon S3 bucket, we are ready to train a machine learning model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_location = f\"s3://{bucket}/{demo_prefix}/output\"\n",
    "# Uncomment below to see specified output location for Algorithm artifacts and outputs\n",
    "# output_location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Train the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train the algorithm there are two groups of parameters that need to be specified, AWS Sagemaker parameters and NannyML Concept Shift detection parameters. You can also find more information about dataset format and AWS Sagemaker parameters in **Hyperparameters** section of [Model Concept Shift Detection - NannyML](https://aws.amazon.com/marketplace/pp/prodview-64nptz3lrs4gc).\n",
    "\n",
    "The NannyML Concept Shift detection parameters needing to be specified are:\n",
    "\n",
    "- **feature_column_names:** A list with the names of the columns used as inputs from the model that\n",
    "    is evaluated.\n",
    "- **y_pred_proba:** The name of the column in the reference data that\n",
    "contains the predicted probabilities.\n",
    "- **y_pred:** The name of the column in the reference data that\n",
    "contains the predicted classes.\n",
    "- **y_true:** The name of the column in the reference data that\n",
    "contains the true classes.\n",
    "- **timestamp_column_name (Optional):** The name of the column in the reference data that\n",
    "contains timestamps.\n",
    "- **metrics:** A list of metrics for which to estimate impact of concept shift. Available options are\n",
    "`accuracy`, `precision`, `recall`, `specificity`, `f1`, `roc_auc` and `magnitude`. Magnitude is a custom concept shift measure ranging between 0, for no concept shift, to 1, theoritical maximum concept shift.\n",
    "- **chunk_size (Optional):** The number of observations in each chunk of data\n",
    "used. Only one chunking argument needs to be provided. For more information about\n",
    "[chunking](https://nannyml.readthedocs.io/en/stable/glossary.html#term-Data-Chunk)\n",
    "configurations check out the [chunking tutorial](https://nannyml.readthedocs.io/en/stable/tutorials/chunking.html#chunking).\n",
    "- **chunk_number (Optional):** The number of chunks to be created out of data provided for each\n",
    "[period](https://nannyml.readthedocs.io/en/stable/tutorials/data_requirements.html#data-periods).\n",
    "- **chunk_period (Optional):** The time period based on which we aggregate the provided data in\n",
    "order to create chunks.\n",
    "- **chunker (Optional):** A NannyML [Chunker object](https://nannyml.readthedocs.io/en/stable/nannyml/nannyml.chunk.html#nannyml.chunk.Chunker) that will handle the aggregation\n",
    "provided data in order to create chunks.\n",
    "- **problem_type:** A string indicating the type of problem being monitored. Currently only `\"classification_binary\"` problems are supported for Concept Shift.\n",
    "- **thresholds (Optional):** The thresholds used to calculate the alert flag. For more information about\n",
    "thresholds, check out the [thresholds tutorial](https://nannyml.readthedocs.io/en/stable/tutorials/thresholds.html#thresholds).\n",
    "- **hyperparameters (Optional):** A dictionary containing hyperparameter specification for the training of the\n",
    "*LGBMClassifier* concept model.\n",
    "- **tune_hyperparameters:** A boolearn specifying whether hyperparameter tuning should be\n",
    "performed. False by default.\n",
    "- **hyperparameter_tuning_config (Optional):** A dictionary containing hyperparameter tuning specification for the hyperparameter tuning of the *LGBMClassifier* concept model.\n",
    "\n",
    "\n",
    "The AWS Sagemaker parameters needing to be specified are:\n",
    "\n",
    "- **problem_type:** A string indicating the type of problem being monitored. Currently only`\"classification_binary\"` problems are supported for Concept Shift.\n",
    "- **data_filename:** A string with the file name that contains the training data.\n",
    "- **data_type:** The file format of the training data file. `csv` is the recomended option.\n",
    "- **parameters:** Algorithm parameters dict, encoded as JSON string. This parameters are passed as kwargs to the corresponding algorithm depending the problem type.\n",
    "\n",
    "<font color='red'>Edit code below as appropriate for your use case. Note that you need to know the list of model `feature_column_names`:<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "nannyml_parameters = {\n",
    "    \"y_pred_proba\": \"y_pred_proba\",\n",
    "    \"y_pred\": \"y_pred\",\n",
    "    \"y_true\": \"repaid\",\n",
    "    \"timestamp_column_name\": \"timestamp\",\n",
    "    \"metrics\": [\"roc_auc\", 'magnitude'],\n",
    "    \"chunk_size\": 5000,\n",
    "    \"problem_type\": \"classification_binary\",\n",
    "    \"feature_column_names\": [\n",
    "        'car_value', 'salary_range', 'debt_to_income_ratio', 'loan_length', 'repaid_loan_on_prev_car', 'size_of_downpayment', 'driver_tenure'\n",
    "    ],\n",
    "}\n",
    "# json.dumps needed due to sagemaker specifications\n",
    "sagemaker_hyperparameters = {\n",
    "    \"data_filename\": reference_dataset.split(\"/\")[-1],\n",
    "    \"data_type\": \"csv\",\n",
    "    \"problem_type\": \"classification_binary\",\n",
    "    \"parameters\": json.dumps(nannyml_parameters),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For information on creating an `Estimator` object, see [documentation](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an estimator object for running a training job\n",
    "estimator = sage.algorithm.AlgorithmEstimator(\n",
    "    algorithm_arn=algo_arn,\n",
    "    base_job_name='nml-concept-shift',\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    input_mode=\"File\",\n",
    "    output_path=output_location,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    hyperparameters=sagemaker_hyperparameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: nml-concept-shift-2023-11-01-18-03-15-619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-01 18:03:15 Starting - Starting the training job...\n",
      "2023-11-01 18:03:32 Starting - Preparing the instances for training......\n",
      "2023-11-01 18:04:26 Downloading - Downloading input data...\n",
      "2023-11-01 18:05:10 Training - Downloading the training image........\u001b[34mINFO:nannyml:Logger object created.\u001b[0m\n",
      "\u001b[34mINFO:nannyml:Hyperparameters read.\u001b[0m\n",
      "\u001b[34mINFO:nannyml:RCS Estimator Instantiated.\u001b[0m\n",
      "\u001b[34mINFO:nannyml:Data loaded.\u001b[0m\n",
      "\u001b[34mINFO:nannyml.base:fitting nannyml_premium.concept_shift.rcs.calculator.ClassificationConceptShiftEstimator\u001b[0m\n",
      "\u001b[34mDEBUG:nannyml.usage_logging:found NML_DISABLE_USAGE_LOGGING key in environment variables. Usage event UsageEvent.RCS_ESTIMATOR_FIT not logged.\u001b[0m\n",
      "\u001b[34mINFO:nannyml:Estimator fit.\u001b[0m\n",
      "\u001b[34mINFO:nannyml.io.store.base:storing object \"nannyml_premium.concept_shift.rcs.calculator.ClassificationConceptShiftEstimator\" to store \"nannyml.io.store.file_store.FilesystemStore\"\u001b[0m\n",
      "\u001b[34mDEBUG:fsspec.local:open file: /opt/ml/model/estimator.pkl\u001b[0m\n",
      "\u001b[34mDEBUG:nannyml.io.store.serializers:serializing object nannyml_premium.concept_shift.rcs.calculator.ClassificationConceptShiftEstimator\u001b[0m\n",
      "\u001b[34mINFO:nannyml:Estimator stored.\u001b[0m\n",
      "\n",
      "2023-11-01 18:06:41 Uploading - Uploading generated training model\n",
      "2023-11-01 18:06:52 Completed - Training job completed\n",
      "Training seconds: 146\n",
      "Billable seconds: 146\n"
     ]
    }
   ],
   "source": [
    "# Run the training job.\n",
    "estimator.fit(\n",
    "    {'training': reference_data}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See this [blog-post](https://aws.amazon.com/blogs/machine-learning/easily-monitor-and-visualize-metrics-while-training-models-on-amazon-sagemaker/) for more information how to visualize metrics during the process. You can also open the training job from [Amazon SageMaker console](https://console.aws.amazon.com/sagemaker/home?#/jobs/) and monitor the metrics/logs in **Monitor** section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4: Deploy model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NannyML's Concept Shift Detection is not designed for real time inference, therefore it is not recommended to use it in this way.**\n",
    "\n",
    "For this reason we are not showcasing the real-time inference feature of Sagemaker Algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Perform Batch Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will perform batch inference using multiple input payloads together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# upload the batch-transform job input files to S3\n",
    "inference_dataset = \"data/synthetic_car_loan_analysis_with_targets.csv\"\n",
    "inference_data = sagemaker_session.upload_data(inference_dataset, bucket=bucket, key_prefix=demo_prefix)\n",
    "# print(\"Transform input uploaded to \" + inference_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model package with name: nannyml-reverse-concept-shift--84a2df2a-2023-11-01-18-07-29-223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: nannyml-reverse-concept-shift--84a2df2a-2023-11-01-18-08-14-710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: nml-concept-shift-2023-11-01-18-08-15-191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................\u001b[34m * Serving Flask app 'inference_server'\n",
      " * Debug mode: off\u001b[0m\n",
      "\u001b[34m#033[31m#033[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.#033[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8080\n",
      " * Running on http://127.0.0.1:8080\u001b[0m\n",
      "\u001b[34m#033[33mPress CTRL+C to quit#033[0m\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [01/Nov/2023 18:13:31] \"GET /ping HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [01/Nov/2023 18:13:31] \"#033[33mGET /execution-parameters HTTP/1.1#033[0m\" 404 -\u001b[0m\n",
      "\u001b[34mReceived POST invocation request.\u001b[0m\n",
      "\u001b[34mfound request data\u001b[0m\n",
      "\u001b[34mcreated string io object\u001b[0m\n",
      "\u001b[34mset buffer to 0\u001b[0m\n",
      "\u001b[34mCreated pandas object.\u001b[0m\n",
      "\u001b[34mEstimation invoked with 50000 rows\u001b[0m\n",
      "\u001b[34mEstimation invoked with columns: ['car_value', 'salary_range', 'debt_to_income_ratio', 'loan_length', 'repaid_loan_on_prev_car', 'size_of_downpayment', 'driver_tenure', 'timestamp', 'y_pred_proba', 'y_pred', 'repaid']\u001b[0m\n",
      "\u001b[35mfound request data\u001b[0m\n",
      "\u001b[35mcreated string io object\u001b[0m\n",
      "\u001b[35mset buffer to 0\u001b[0m\n",
      "\u001b[35mCreated pandas object.\u001b[0m\n",
      "\u001b[35mEstimation invoked with 50000 rows\u001b[0m\n",
      "\u001b[35mEstimation invoked with columns: ['car_value', 'salary_range', 'debt_to_income_ratio', 'loan_length', 'repaid_loan_on_prev_car', 'size_of_downpayment', 'driver_tenure', 'timestamp', 'y_pred_proba', 'y_pred', 'repaid']\u001b[0m\n",
      "\u001b[32m2023-11-01T18:13:31.591:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [01/Nov/2023 18:13:35] \"POST /invocations HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [01/Nov/2023 18:13:35] \"POST /invocations HTTP/1.1\" 200 -\u001b[0m\n",
      "\n",
      "\u001b[34m * Serving Flask app 'inference_server'\n",
      " * Debug mode: off\u001b[0m\n",
      "\u001b[34m#033[31m#033[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.#033[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8080\n",
      " * Running on http://127.0.0.1:8080\u001b[0m\n",
      "\u001b[34m#033[33mPress CTRL+C to quit#033[0m\u001b[0m\n",
      "\u001b[35m * Serving Flask app 'inference_server'\n",
      " * Debug mode: off\u001b[0m\n",
      "\u001b[35m#033[31m#033[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.#033[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8080\n",
      " * Running on http://127.0.0.1:8080\u001b[0m\n",
      "\u001b[35m#033[33mPress CTRL+C to quit#033[0m\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [01/Nov/2023 18:13:31] \"GET /ping HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [01/Nov/2023 18:13:31] \"#033[33mGET /execution-parameters HTTP/1.1#033[0m\" 404 -\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [01/Nov/2023 18:13:31] \"GET /ping HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [01/Nov/2023 18:13:31] \"#033[33mGET /execution-parameters HTTP/1.1#033[0m\" 404 -\u001b[0m\n",
      "\u001b[34mReceived POST invocation request.\u001b[0m\n",
      "\u001b[35mReceived POST invocation request.\u001b[0m\n",
      "\u001b[34mfound request data\u001b[0m\n",
      "\u001b[34mcreated string io object\u001b[0m\n",
      "\u001b[34mset buffer to 0\u001b[0m\n",
      "\u001b[34mCreated pandas object.\u001b[0m\n",
      "\u001b[34mEstimation invoked with 50000 rows\u001b[0m\n",
      "\u001b[34mEstimation invoked with columns: ['car_value', 'salary_range', 'debt_to_income_ratio', 'loan_length', 'repaid_loan_on_prev_car', 'size_of_downpayment', 'driver_tenure', 'timestamp', 'y_pred_proba', 'y_pred', 'repaid']\u001b[0m\n",
      "\u001b[35mfound request data\u001b[0m\n",
      "\u001b[35mcreated string io object\u001b[0m\n",
      "\u001b[35mset buffer to 0\u001b[0m\n",
      "\u001b[35mCreated pandas object.\u001b[0m\n",
      "\u001b[35mEstimation invoked with 50000 rows\u001b[0m\n",
      "\u001b[35mEstimation invoked with columns: ['car_value', 'salary_range', 'debt_to_income_ratio', 'loan_length', 'repaid_loan_on_prev_car', 'size_of_downpayment', 'driver_tenure', 'timestamp', 'y_pred_proba', 'y_pred', 'repaid']\u001b[0m\n",
      "\u001b[32m2023-11-01T18:13:31.591:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [01/Nov/2023 18:13:35] \"POST /invocations HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [01/Nov/2023 18:13:35] \"POST /invocations HTTP/1.1\" 200 -\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Run the batch-transform job\n",
    "transformer = estimator.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    output_path=output_location\n",
    ")\n",
    "transformer.transform(inference_data, content_type=\"text/csv\")\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**View Results of Performance Estimation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"7\" halign=\"left\">chunk</th>\n",
       "      <th colspan=\"7\" halign=\"left\">roc_auc</th>\n",
       "      <th colspan=\"7\" halign=\"left\">magnitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>chunk_index</th>\n",
       "      <th>start_index</th>\n",
       "      <th>end_index</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>period</th>\n",
       "      <th>value</th>\n",
       "      <th>sampling_error</th>\n",
       "      <th>upper_confidence_boundary</th>\n",
       "      <th>...</th>\n",
       "      <th>upper_threshold</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>alert</th>\n",
       "      <th>value</th>\n",
       "      <th>sampling_error</th>\n",
       "      <th>upper_confidence_boundary</th>\n",
       "      <th>lower_confidence_boundary</th>\n",
       "      <th>upper_threshold</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>alert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0:4999]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4999</td>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>2018-01-31 06:27:16.848</td>\n",
       "      <td>reference</td>\n",
       "      <td>0.970999</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.976431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974539</td>\n",
       "      <td>0.955786</td>\n",
       "      <td>False</td>\n",
       "      <td>0.053040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059474</td>\n",
       "      <td>0.0501</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[5000:9999]</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>9999</td>\n",
       "      <td>2018-01-31 06:36:00</td>\n",
       "      <td>2018-03-02 13:03:16.848</td>\n",
       "      <td>reference</td>\n",
       "      <td>0.964029</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.969461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974539</td>\n",
       "      <td>0.955786</td>\n",
       "      <td>False</td>\n",
       "      <td>0.054423</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059474</td>\n",
       "      <td>0.0501</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[10000:14999]</td>\n",
       "      <td>2</td>\n",
       "      <td>10000</td>\n",
       "      <td>14999</td>\n",
       "      <td>2018-03-02 13:12:00</td>\n",
       "      <td>2018-04-01 19:39:16.848</td>\n",
       "      <td>reference</td>\n",
       "      <td>0.968708</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.974140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974539</td>\n",
       "      <td>0.955786</td>\n",
       "      <td>False</td>\n",
       "      <td>0.054312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059474</td>\n",
       "      <td>0.0501</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[15000:19999]</td>\n",
       "      <td>3</td>\n",
       "      <td>15000</td>\n",
       "      <td>19999</td>\n",
       "      <td>2018-04-01 19:48:00</td>\n",
       "      <td>2018-05-02 02:15:16.848</td>\n",
       "      <td>reference</td>\n",
       "      <td>0.963728</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.969160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974539</td>\n",
       "      <td>0.955786</td>\n",
       "      <td>False</td>\n",
       "      <td>0.054494</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059474</td>\n",
       "      <td>0.0501</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[20000:24999]</td>\n",
       "      <td>4</td>\n",
       "      <td>20000</td>\n",
       "      <td>24999</td>\n",
       "      <td>2018-05-02 02:24:00</td>\n",
       "      <td>2018-06-01 08:51:16.848</td>\n",
       "      <td>reference</td>\n",
       "      <td>0.960701</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.966133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974539</td>\n",
       "      <td>0.955786</td>\n",
       "      <td>False</td>\n",
       "      <td>0.059166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059474</td>\n",
       "      <td>0.0501</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[25000:29999]</td>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "      <td>29999</td>\n",
       "      <td>2018-06-01 09:00:00</td>\n",
       "      <td>2018-07-01 15:27:16.848</td>\n",
       "      <td>reference</td>\n",
       "      <td>0.962452</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.967884</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974539</td>\n",
       "      <td>0.955786</td>\n",
       "      <td>False</td>\n",
       "      <td>0.055099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059474</td>\n",
       "      <td>0.0501</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[30000:34999]</td>\n",
       "      <td>6</td>\n",
       "      <td>30000</td>\n",
       "      <td>34999</td>\n",
       "      <td>2018-07-01 15:36:00</td>\n",
       "      <td>2018-07-31 22:03:16.848</td>\n",
       "      <td>reference</td>\n",
       "      <td>0.966094</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.971526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974539</td>\n",
       "      <td>0.955786</td>\n",
       "      <td>False</td>\n",
       "      <td>0.054607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059474</td>\n",
       "      <td>0.0501</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[35000:39999]</td>\n",
       "      <td>7</td>\n",
       "      <td>35000</td>\n",
       "      <td>39999</td>\n",
       "      <td>2018-07-31 22:12:00</td>\n",
       "      <td>2018-08-31 04:39:16.848</td>\n",
       "      <td>reference</td>\n",
       "      <td>0.964554</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.969986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974539</td>\n",
       "      <td>0.955786</td>\n",
       "      <td>False</td>\n",
       "      <td>0.053702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059474</td>\n",
       "      <td>0.0501</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[40000:44999]</td>\n",
       "      <td>8</td>\n",
       "      <td>40000</td>\n",
       "      <td>44999</td>\n",
       "      <td>2018-08-31 04:48:00</td>\n",
       "      <td>2018-09-30 11:15:16.848</td>\n",
       "      <td>reference</td>\n",
       "      <td>0.968280</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.973712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974539</td>\n",
       "      <td>0.955786</td>\n",
       "      <td>False</td>\n",
       "      <td>0.054890</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059474</td>\n",
       "      <td>0.0501</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[45000:49999]</td>\n",
       "      <td>9</td>\n",
       "      <td>45000</td>\n",
       "      <td>49999</td>\n",
       "      <td>2018-09-30 11:24:00</td>\n",
       "      <td>2018-10-30 17:51:16.848</td>\n",
       "      <td>reference</td>\n",
       "      <td>0.962080</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.967512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974539</td>\n",
       "      <td>0.955786</td>\n",
       "      <td>False</td>\n",
       "      <td>0.054141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059474</td>\n",
       "      <td>0.0501</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0:4999]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4999</td>\n",
       "      <td>2018-10-30 18:00:00</td>\n",
       "      <td>2018-11-30 00:27:16.848</td>\n",
       "      <td>analysis</td>\n",
       "      <td>0.962994</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.968426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974539</td>\n",
       "      <td>0.955786</td>\n",
       "      <td>False</td>\n",
       "      <td>0.053793</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059474</td>\n",
       "      <td>0.0501</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[5000:9999]</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>9999</td>\n",
       "      <td>2018-11-30 00:36:00</td>\n",
       "      <td>2018-12-30 07:03:16.848</td>\n",
       "      <td>analysis</td>\n",
       "      <td>0.965751</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.971183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974539</td>\n",
       "      <td>0.955786</td>\n",
       "      <td>False</td>\n",
       "      <td>0.052550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059474</td>\n",
       "      <td>0.0501</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[10000:14999]</td>\n",
       "      <td>2</td>\n",
       "      <td>10000</td>\n",
       "      <td>14999</td>\n",
       "      <td>2018-12-30 07:12:00</td>\n",
       "      <td>2019-01-29 13:39:16.848</td>\n",
       "      <td>analysis</td>\n",
       "      <td>0.969490</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.974922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974539</td>\n",
       "      <td>0.955786</td>\n",
       "      <td>False</td>\n",
       "      <td>0.053628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059474</td>\n",
       "      <td>0.0501</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[15000:19999]</td>\n",
       "      <td>3</td>\n",
       "      <td>15000</td>\n",
       "      <td>19999</td>\n",
       "      <td>2019-01-29 13:48:00</td>\n",
       "      <td>2019-02-28 20:15:16.848</td>\n",
       "      <td>analysis</td>\n",
       "      <td>0.961620</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.967052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974539</td>\n",
       "      <td>0.955786</td>\n",
       "      <td>False</td>\n",
       "      <td>0.055655</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059474</td>\n",
       "      <td>0.0501</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[20000:24999]</td>\n",
       "      <td>4</td>\n",
       "      <td>20000</td>\n",
       "      <td>24999</td>\n",
       "      <td>2019-02-28 20:24:00</td>\n",
       "      <td>2019-03-31 02:51:16.848</td>\n",
       "      <td>analysis</td>\n",
       "      <td>0.963987</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.969419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974539</td>\n",
       "      <td>0.955786</td>\n",
       "      <td>False</td>\n",
       "      <td>0.054735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059474</td>\n",
       "      <td>0.0501</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[25000:29999]</td>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "      <td>29999</td>\n",
       "      <td>2019-03-31 03:00:00</td>\n",
       "      <td>2019-04-30 09:27:16.848</td>\n",
       "      <td>analysis</td>\n",
       "      <td>0.956955</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.962387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974539</td>\n",
       "      <td>0.955786</td>\n",
       "      <td>False</td>\n",
       "      <td>0.075756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059474</td>\n",
       "      <td>0.0501</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[30000:34999]</td>\n",
       "      <td>6</td>\n",
       "      <td>30000</td>\n",
       "      <td>34999</td>\n",
       "      <td>2019-04-30 09:36:00</td>\n",
       "      <td>2019-05-30 16:03:16.848</td>\n",
       "      <td>analysis</td>\n",
       "      <td>0.933329</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.938761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974539</td>\n",
       "      <td>0.955786</td>\n",
       "      <td>True</td>\n",
       "      <td>0.088310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059474</td>\n",
       "      <td>0.0501</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[35000:39999]</td>\n",
       "      <td>7</td>\n",
       "      <td>35000</td>\n",
       "      <td>39999</td>\n",
       "      <td>2019-05-30 16:12:00</td>\n",
       "      <td>2019-06-29 22:39:16.848</td>\n",
       "      <td>analysis</td>\n",
       "      <td>0.942431</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.947863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974539</td>\n",
       "      <td>0.955786</td>\n",
       "      <td>True</td>\n",
       "      <td>0.084602</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059474</td>\n",
       "      <td>0.0501</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[40000:44999]</td>\n",
       "      <td>8</td>\n",
       "      <td>40000</td>\n",
       "      <td>44999</td>\n",
       "      <td>2019-06-29 22:48:00</td>\n",
       "      <td>2019-07-30 05:15:16.848</td>\n",
       "      <td>analysis</td>\n",
       "      <td>0.952643</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.958076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974539</td>\n",
       "      <td>0.955786</td>\n",
       "      <td>True</td>\n",
       "      <td>0.073059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059474</td>\n",
       "      <td>0.0501</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[45000:49999]</td>\n",
       "      <td>9</td>\n",
       "      <td>45000</td>\n",
       "      <td>49999</td>\n",
       "      <td>2019-07-30 05:24:00</td>\n",
       "      <td>2019-08-29 11:51:16.848</td>\n",
       "      <td>analysis</td>\n",
       "      <td>0.935890</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.941322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974539</td>\n",
       "      <td>0.955786</td>\n",
       "      <td>True</td>\n",
       "      <td>0.083401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059474</td>\n",
       "      <td>0.0501</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            chunk                                                         \\\n",
       "              key chunk_index start_index end_index           start_date   \n",
       "0        [0:4999]           0           0      4999  2018-01-01 00:00:00   \n",
       "1     [5000:9999]           1        5000      9999  2018-01-31 06:36:00   \n",
       "2   [10000:14999]           2       10000     14999  2018-03-02 13:12:00   \n",
       "3   [15000:19999]           3       15000     19999  2018-04-01 19:48:00   \n",
       "4   [20000:24999]           4       20000     24999  2018-05-02 02:24:00   \n",
       "5   [25000:29999]           5       25000     29999  2018-06-01 09:00:00   \n",
       "6   [30000:34999]           6       30000     34999  2018-07-01 15:36:00   \n",
       "7   [35000:39999]           7       35000     39999  2018-07-31 22:12:00   \n",
       "8   [40000:44999]           8       40000     44999  2018-08-31 04:48:00   \n",
       "9   [45000:49999]           9       45000     49999  2018-09-30 11:24:00   \n",
       "10       [0:4999]           0           0      4999  2018-10-30 18:00:00   \n",
       "11    [5000:9999]           1        5000      9999  2018-11-30 00:36:00   \n",
       "12  [10000:14999]           2       10000     14999  2018-12-30 07:12:00   \n",
       "13  [15000:19999]           3       15000     19999  2019-01-29 13:48:00   \n",
       "14  [20000:24999]           4       20000     24999  2019-02-28 20:24:00   \n",
       "15  [25000:29999]           5       25000     29999  2019-03-31 03:00:00   \n",
       "16  [30000:34999]           6       30000     34999  2019-04-30 09:36:00   \n",
       "17  [35000:39999]           7       35000     39999  2019-05-30 16:12:00   \n",
       "18  [40000:44999]           8       40000     44999  2019-06-29 22:48:00   \n",
       "19  [45000:49999]           9       45000     49999  2019-07-30 05:24:00   \n",
       "\n",
       "                                         roc_auc                 \\\n",
       "                   end_date     period     value sampling_error   \n",
       "0   2018-01-31 06:27:16.848  reference  0.970999       0.001811   \n",
       "1   2018-03-02 13:03:16.848  reference  0.964029       0.001811   \n",
       "2   2018-04-01 19:39:16.848  reference  0.968708       0.001811   \n",
       "3   2018-05-02 02:15:16.848  reference  0.963728       0.001811   \n",
       "4   2018-06-01 08:51:16.848  reference  0.960701       0.001811   \n",
       "5   2018-07-01 15:27:16.848  reference  0.962452       0.001811   \n",
       "6   2018-07-31 22:03:16.848  reference  0.966094       0.001811   \n",
       "7   2018-08-31 04:39:16.848  reference  0.964554       0.001811   \n",
       "8   2018-09-30 11:15:16.848  reference  0.968280       0.001811   \n",
       "9   2018-10-30 17:51:16.848  reference  0.962080       0.001811   \n",
       "10  2018-11-30 00:27:16.848   analysis  0.962994       0.001811   \n",
       "11  2018-12-30 07:03:16.848   analysis  0.965751       0.001811   \n",
       "12  2019-01-29 13:39:16.848   analysis  0.969490       0.001811   \n",
       "13  2019-02-28 20:15:16.848   analysis  0.961620       0.001811   \n",
       "14  2019-03-31 02:51:16.848   analysis  0.963987       0.001811   \n",
       "15  2019-04-30 09:27:16.848   analysis  0.956955       0.001811   \n",
       "16  2019-05-30 16:03:16.848   analysis  0.933329       0.001811   \n",
       "17  2019-06-29 22:39:16.848   analysis  0.942431       0.001811   \n",
       "18  2019-07-30 05:15:16.848   analysis  0.952643       0.001811   \n",
       "19  2019-08-29 11:51:16.848   analysis  0.935890       0.001811   \n",
       "\n",
       "                              ...                                         \\\n",
       "   upper_confidence_boundary  ... upper_threshold lower_threshold  alert   \n",
       "0                   0.976431  ...        0.974539        0.955786  False   \n",
       "1                   0.969461  ...        0.974539        0.955786  False   \n",
       "2                   0.974140  ...        0.974539        0.955786  False   \n",
       "3                   0.969160  ...        0.974539        0.955786  False   \n",
       "4                   0.966133  ...        0.974539        0.955786  False   \n",
       "5                   0.967884  ...        0.974539        0.955786  False   \n",
       "6                   0.971526  ...        0.974539        0.955786  False   \n",
       "7                   0.969986  ...        0.974539        0.955786  False   \n",
       "8                   0.973712  ...        0.974539        0.955786  False   \n",
       "9                   0.967512  ...        0.974539        0.955786  False   \n",
       "10                  0.968426  ...        0.974539        0.955786  False   \n",
       "11                  0.971183  ...        0.974539        0.955786  False   \n",
       "12                  0.974922  ...        0.974539        0.955786  False   \n",
       "13                  0.967052  ...        0.974539        0.955786  False   \n",
       "14                  0.969419  ...        0.974539        0.955786  False   \n",
       "15                  0.962387  ...        0.974539        0.955786  False   \n",
       "16                  0.938761  ...        0.974539        0.955786   True   \n",
       "17                  0.947863  ...        0.974539        0.955786   True   \n",
       "18                  0.958076  ...        0.974539        0.955786   True   \n",
       "19                  0.941322  ...        0.974539        0.955786   True   \n",
       "\n",
       "   magnitude                                           \\\n",
       "       value sampling_error upper_confidence_boundary   \n",
       "0   0.053040            NaN                       NaN   \n",
       "1   0.054423            NaN                       NaN   \n",
       "2   0.054312            NaN                       NaN   \n",
       "3   0.054494            NaN                       NaN   \n",
       "4   0.059166            NaN                       NaN   \n",
       "5   0.055099            NaN                       NaN   \n",
       "6   0.054607            NaN                       NaN   \n",
       "7   0.053702            NaN                       NaN   \n",
       "8   0.054890            NaN                       NaN   \n",
       "9   0.054141            NaN                       NaN   \n",
       "10  0.053793            NaN                       NaN   \n",
       "11  0.052550            NaN                       NaN   \n",
       "12  0.053628            NaN                       NaN   \n",
       "13  0.055655            NaN                       NaN   \n",
       "14  0.054735            NaN                       NaN   \n",
       "15  0.075756            NaN                       NaN   \n",
       "16  0.088310            NaN                       NaN   \n",
       "17  0.084602            NaN                       NaN   \n",
       "18  0.073059            NaN                       NaN   \n",
       "19  0.083401            NaN                       NaN   \n",
       "\n",
       "                                                                     \n",
       "   lower_confidence_boundary upper_threshold lower_threshold  alert  \n",
       "0                        NaN        0.059474          0.0501  False  \n",
       "1                        NaN        0.059474          0.0501  False  \n",
       "2                        NaN        0.059474          0.0501  False  \n",
       "3                        NaN        0.059474          0.0501  False  \n",
       "4                        NaN        0.059474          0.0501  False  \n",
       "5                        NaN        0.059474          0.0501  False  \n",
       "6                        NaN        0.059474          0.0501  False  \n",
       "7                        NaN        0.059474          0.0501  False  \n",
       "8                        NaN        0.059474          0.0501  False  \n",
       "9                        NaN        0.059474          0.0501  False  \n",
       "10                       NaN        0.059474          0.0501  False  \n",
       "11                       NaN        0.059474          0.0501  False  \n",
       "12                       NaN        0.059474          0.0501  False  \n",
       "13                       NaN        0.059474          0.0501  False  \n",
       "14                       NaN        0.059474          0.0501  False  \n",
       "15                       NaN        0.059474          0.0501   True  \n",
       "16                       NaN        0.059474          0.0501   True  \n",
       "17                       NaN        0.059474          0.0501   True  \n",
       "18                       NaN        0.059474          0.0501   True  \n",
       "19                       NaN        0.059474          0.0501   True  \n",
       "\n",
       "[20 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.read_csv(transformer.output_path + \"/\" + inference_dataset.split(\"/\")[-1] + \".out\", header = [0,1])\n",
    "# results.to_csv(\"data/synthetic_car_loan_rcs_output.csv\", index=False)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Delete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting model with name: nannyml-reverse-concept-shift--84a2df2a-2023-11-01-18-08-14-710\n"
     ]
    }
   ],
   "source": [
    "transformer.delete_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Unsubscribe to the listing (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to unsubscribe to the algorithm, follow these steps. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to unsubscribe to product from AWS Marketplace**:\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_indust)\n",
    "2. Locate the listing that you want to cancel the subscription for, and then choose __Cancel Subscription__  to cancel the subscription.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
